{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:52:11.497773Z","iopub.execute_input":"2025-04-09T13:52:11.498103Z","iopub.status.idle":"2025-04-09T13:52:11.721014Z","shell.execute_reply.started":"2025-04-09T13:52:11.498070Z","shell.execute_reply":"2025-04-09T13:52:11.719965Z"}},"outputs":[{"name":"stdout","text":"Wed Apr  9 13:52:11 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   47C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   52C    P8             12W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:52:55.073625Z","iopub.execute_input":"2025-04-09T13:52:55.073950Z","iopub.status.idle":"2025-04-09T13:52:55.217904Z","shell.execute_reply.started":"2025-04-09T13:52:55.073920Z","shell.execute_reply":"2025-04-09T13:52:55.217109Z"}},"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile matrix_mul_refined.cu\n#include <stdio.h>\n#include <stdlib.h>\n#include <cuda_runtime.h>\n#include <math.h> // For fabs\n\n// Simple CUDA Error Handling Macro\n#define CHECK_CUDA_ERROR(err) \\\n    if (err != cudaSuccess) { \\\n        fprintf(stderr, \"CUDA Error at %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n        exit(EXIT_FAILURE); \\\n    }\n\n// Tile dimension (adjust based on GPU architecture, e.g., 16 or 32)\n#define TILE_DIM 16\n\n// Tiled Matrix Multiplication Kernel (C = A * B)\n__global__ void matrixMulTiledKernel(const float *A, const float *B, float *C, int width) {\n    __shared__ float ds_A[TILE_DIM][TILE_DIM];\n    __shared__ float ds_B[TILE_DIM][TILE_DIM];\n\n    int tx = threadIdx.x;   // Thread index within block (col)\n    int ty = threadIdx.y;   // Thread index within block (row)\n    int row = blockIdx.y * TILE_DIM + ty; // Global row index for C\n    int col = blockIdx.x * TILE_DIM + tx; // Global col index for C\n\n    float Cvalue = 0.0f;\n    int numTiles = (width + TILE_DIM - 1) / TILE_DIM;\n\n    // Loop over tiles\n    for (int t = 0; t < numTiles; ++t) {\n        // Load tile for A from global memory to shared memory\n        int A_row_idx = row;\n        int A_col_idx = t * TILE_DIM + tx;\n        if (A_row_idx < width && A_col_idx < width) {\n            ds_A[ty][tx] = A[A_row_idx * width + A_col_idx];\n        } else {\n            ds_A[ty][tx] = 0.0f;\n        }\n\n        // Load tile for B from global memory to shared memory\n        int B_row_idx = t * TILE_DIM + ty;\n        int B_col_idx = col;\n        if (B_row_idx < width && B_col_idx < width) {\n            ds_B[ty][tx] = B[B_row_idx * width + B_col_idx];\n        } else {\n            ds_B[ty][tx] = 0.0f;\n        }\n\n        __syncthreads(); // Ensure tiles are loaded before computation\n\n        // Multiply tiles loaded in shared memory\n        for (int k = 0; k < TILE_DIM; ++k) {\n             // Check if the k-th element corresponds to a valid element\n             // in the original matrices (handles non-perfect divisibility)\n             // Note: The padding above largely handles this, but this is belt-and-suspenders.\n             if (t * TILE_DIM + k < width) {\n                Cvalue += ds_A[ty][k] * ds_B[k][tx];\n             }\n        }\n\n        __syncthreads(); // Ensure computation is done before loading next tile\n    }\n\n    // Write result Cvalue to global memory\n    if (row < width && col < width) {\n        C[row * width + col] = Cvalue;\n    }\n}\n\n// Basic CPU Matrix Multiplication for Verification\nvoid matrixMulCPU(const float *A, const float *B, float *C, int width) {\n    for (int row = 0; row < width; ++row) {\n        for (int col = 0; col < width; ++col) {\n            float sum = 0.0f;\n            for (int k = 0; k < width; ++k) {\n                sum += A[row * width + k] * B[k * width + col];\n            }\n            C[row * width + col] = sum;\n        }\n    }\n}\n\nint main() {\n    // Use a multiple of TILE_DIM for simplicity, but kernel handles others\n    int width = 1024;\n    printf(\"Matrix Multiplication (Tiled CUDA)\\nMatrix dimensions: %d x %d\\n\", width, width);\n    printf(\"Tile dimensions: %d x %d\\n\", TILE_DIM, TILE_DIM);\n\n    size_t size = (size_t)width * width * sizeof(float);\n    float mb_size = (float)size / (1024 * 1024);\n\n    // Host memory\n    float *h_A      = (float*)malloc(size);\n    float *h_B      = (float*)malloc(size);\n    float *h_C_gpu  = (float*)malloc(size);\n    float *h_C_cpu  = NULL; // Allocate only if verifying\n    bool verify = true;     // Set to false to skip CPU verification\n\n    if (!h_A || !h_B || !h_C_gpu) {\n        fprintf(stderr, \"Failed to allocate host matrices!\\n\"); return EXIT_FAILURE;\n    }\n    if (verify) {\n        h_C_cpu = (float*)malloc(size);\n        if (!h_C_cpu) { fprintf(stderr, \"Failed to allocate host CPU result matrix!\\n\"); verify = false; }\n    }\n\n    // Initialize host matrices (simple values)\n    printf(\"Initializing host matrices (%.2f MB each)...\\n\", mb_size);\n    for (int i = 0; i < width * width; ++i) {\n        h_A[i] = (float)(i % width + 1) / width; // Some pattern\n        h_B[i] = (float)(i / width + 1) / width; // Some pattern\n    }\n\n    // Device memory\n    float *d_A = NULL, *d_B = NULL, *d_C = NULL;\n    printf(\"Allocating %.2f MB on device...\\n\", 3.0f * mb_size);\n    CHECK_CUDA_ERROR(cudaMalloc(&d_A, size));\n    CHECK_CUDA_ERROR(cudaMalloc(&d_B, size));\n    CHECK_CUDA_ERROR(cudaMalloc(&d_C, size));\n\n    // Copy data Host -> Device\n    printf(\"Copying data to device...\\n\");\n    CHECK_CUDA_ERROR(cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice));\n    CHECK_CUDA_ERROR(cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice));\n\n    // Kernel launch configuration (2D grid, 2D block)\n    dim3 blockSize(TILE_DIM, TILE_DIM);\n    dim3 gridSize((width + TILE_DIM - 1) / TILE_DIM, (width + TILE_DIM - 1) / TILE_DIM);\n    printf(\"Launching kernel (Grid: %dx%d, Block: %dx%d)...\\n\",\n           gridSize.x, gridSize.y, blockSize.x, blockSize.y);\n\n    // --- Use CUDA events for timing (more accurate than CPU timers) ---\n    cudaEvent_t start, stop;\n    CHECK_CUDA_ERROR(cudaEventCreate(&start));\n    CHECK_CUDA_ERROR(cudaEventCreate(&stop));\n\n    CHECK_CUDA_ERROR(cudaEventRecord(start)); // Record start time\n\n    // Launch kernel\n    matrixMulTiledKernel<<<gridSize, blockSize>>>(d_A, d_B, d_C, width);\n\n    CHECK_CUDA_ERROR(cudaEventRecord(stop));   // Record stop time\n    CHECK_CUDA_ERROR(cudaEventSynchronize(stop));// Wait for the event to complete\n\n    CHECK_CUDA_ERROR(cudaPeekAtLastError()); // Check for launch errors\n    // cudaDeviceSynchronize() is implicitly done by cudaEventSynchronize(stop) above\n\n    float milliseconds = 0;\n    CHECK_CUDA_ERROR(cudaEventElapsedTime(&milliseconds, start, stop));\n    printf(\"Kernel execution time: %.3f ms\\n\", milliseconds);\n    double gflops = 2.0 * width * width * width / (milliseconds / 1000.0) / 1e9;\n    printf(\"Performance: %.2f GFLOPS\\n\", gflops);\n\n    // Copy data Device -> Host\n    printf(\"Copying result back to host...\\n\");\n    CHECK_CUDA_ERROR(cudaMemcpy(h_C_gpu, d_C, size, cudaMemcpyDeviceToHost));\n\n    // Verification\n    if (verify) {\n        printf(\"Performing CPU verification...\\n\");\n        matrixMulCPU(h_A, h_B, h_C_cpu, width);\n        printf(\"Comparing results...\\n\");\n\n        double max_error = 0.0;\n        double avg_error = 0.0;\n        int errors = 0;\n        float tolerance = 1e-3f; // Adjust tolerance as needed\n\n        for (int i = 0; i < width * width; ++i) {\n            double error = fabs(h_C_gpu[i] - h_C_cpu[i]);\n            if (error > max_error) max_error = error;\n            avg_error += error;\n            if (error > tolerance) {\n                errors++;\n            }\n        }\n        avg_error /= (width * width);\n\n        if (errors == 0) {\n            printf(\"Verification Successful! Max Error: %e, Avg Error: %e\\n\", max_error, avg_error);\n        } else {\n            printf(\"Verification FAILED! Errors: %d, Max Error: %e, Avg Error: %e\\n\", errors, max_error, avg_error);\n        }\n    }\n\n    // Cleanup\n    printf(\"Freeing memory...\\n\");\n    CHECK_CUDA_ERROR(cudaEventDestroy(start));\n    CHECK_CUDA_ERROR(cudaEventDestroy(stop));\n    CHECK_CUDA_ERROR(cudaFree(d_A));\n    CHECK_CUDA_ERROR(cudaFree(d_B));\n    CHECK_CUDA_ERROR(cudaFree(d_C));\n    free(h_A);\n    free(h_B);\n    free(h_C_gpu);\n    if (h_C_cpu) free(h_C_cpu);\n\n    printf(\"Matrix multiplication complete.\\n\");\n    return EXIT_SUCCESS;\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:53:43.419282Z","iopub.execute_input":"2025-04-09T13:53:43.419668Z","iopub.status.idle":"2025-04-09T13:53:43.427450Z","shell.execute_reply.started":"2025-04-09T13:53:43.419635Z","shell.execute_reply":"2025-04-09T13:53:43.426718Z"}},"outputs":[{"name":"stdout","text":"Writing matrix_mul_refined.cu\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!nvcc matrix_mul_refined.cu -o matrix_mul_refined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:54:54.073305Z","iopub.execute_input":"2025-04-09T13:54:54.073658Z","iopub.status.idle":"2025-04-09T13:54:57.325076Z","shell.execute_reply.started":"2025-04-09T13:54:54.073631Z","shell.execute_reply":"2025-04-09T13:54:57.324090Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!./matrix_mul_refined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T13:55:03.513074Z","iopub.execute_input":"2025-04-09T13:55:03.513395Z","iopub.status.idle":"2025-04-09T13:55:11.198501Z","shell.execute_reply.started":"2025-04-09T13:55:03.513368Z","shell.execute_reply":"2025-04-09T13:55:11.197730Z"}},"outputs":[{"name":"stdout","text":"Matrix Multiplication (Tiled CUDA)\nMatrix dimensions: 1024 x 1024\nTile dimensions: 16 x 16\nInitializing host matrices (4.00 MB each)...\nAllocating 12.00 MB on device...\nCopying data to device...\nLaunching kernel (Grid: 64x64, Block: 16x16)...\nKernel execution time: 141.489 ms\nPerformance: 15.18 GFLOPS\nCopying result back to host...\nPerforming CPU verification...\nComparing results...\nVerification Successful! Max Error: 0.000000e+00, Avg Error: 0.000000e+00\nFreeing memory...\nMatrix multiplication complete.\n","output_type":"stream"}],"execution_count":6}]}