## üöÄ High Performance Computing Laboratory - SPPU üöÄ

[![GitHub license](https://img.shields.io/github/license/kunalPisolkar24/HPC_Lab)](https://github.com/kunalPisolkar24/HPC_Lab/blob/main/LICENSE)
![GitHub last commit](https://img.shields.io/github/last-commit/kunalPisolkar24/HPC_Lab)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/kunalPisolkar24/HPC_Lab)

Welcome to the repository for the **High Performance Computing (410255)** laboratory course, part of the Fourth Year Computer Engineering curriculum (2019 Course) at Savitribai Phule Pune University. This repository is dedicated to providing practical implementations and resources for exploring parallel programming models, performance analysis, and techniques to parallelize algorithms for modern computing architectures.

üèõÔ∏è **Course Information:**

| Feature | Description |
|---|---|
| University | Savitribai Phule Pune University |
| Course Name | High Performance Computing |
| Course Code | 410255 |
| Credit | 01 |
| Practical Sessions | 02 Hours/Week |
| Examination Scheme | Term Work: 50 Marks <br> Practical Exam: 50 Marks |

üéØ **Learning Objectives:**

*   To understand different parallel programming models.
*   To analyze the performance and modeling of parallel programs.
*   To illustrate the various techniques to parallelize the algorithm.
*   To implement parallel communication operations.
*   To discriminate CUDA Architecture and its components.
*   To Understand Scope of Parallel Computing and its search algorithms.

üí° **Course Outcomes:**

Upon successful completion of this laboratory course, students will be able to:

*   **CO1:** Understand various Parallel Paradigms.
*   **CO2:** Design and Develop an efficient parallel algorithm to solve given problems.
*   **CO3:** Illustrate data communication operations on various parallel architectures.
*   **CO4:** Analyze and measure the performance of modern parallel computing systems.
*   **CO5:** Apply CUDA architecture for parallel programming.
*   **CO6:** Analyze the performance of HPC applications.

üíª **Practical Implementations:**

| Practical No. | Description |
|---|---|
| 1 | **Parallel Graph Traversal (OpenMP):** <br> Design and implement Parallel Breadth First Search (BFS) and Depth First Search (DFS) based on existing algorithms using OpenMP. Use a Tree or an undirected graph for BFS and DFS. |
| 2 | **Parallel Sorting Algorithms (OpenMP):** <br> Write a program to implement Parallel Bubble Sort and Merge sort using OpenMP. Use existing algorithms and measure the performance of sequential and parallel algorithms. |
| 3 | **Parallel Reduction Operations:** <br> Implement Min, Max, Sum, and Average operations using Parallel Reduction techniques. |
| 4 | **CUDA Programming Basics:** <br> Write CUDA C Programs for: <br> 1. Addition of two large vectors. <br> 2. Matrix Multiplication. |

üåü **Mini Project - Parallel Quicksort Algorithm:**

Evaluate the performance enhancement of a parallel Quicksort Algorithm using MPI (Message Passing Interface). This project involves implementing Quicksort in a distributed memory paradigm and analyzing its speedup and efficiency.

üöÄ **Getting Started:**

Navigate to the specific practical implementation directory for detailed instructions, code examples, and any necessary datasets.

üôå **Contributions:**

Contributions, improvements, and feedback are highly encouraged! If you have any enhancements, bug fixes, or additional examples that could benefit others, please feel free to open a pull request. Kindly refer to the `CONTRIBUTING.md` file for contribution guidelines (if you plan to add one).

üìÑ **License:**

This repository is distributed under the MIT License. You are free to use, modify, and distribute the code for educational and personal projects. See the `LICENSE` file for more details.

Let's unlock the power of parallel processing and accelerate our computations!